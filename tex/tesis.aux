\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\providecommand \oddpage@label [2]{}
\selectlanguage *{spanish}
\@writefile{toc}{\selectlanguage *{spanish}}
\@writefile{lof}{\selectlanguage *{spanish}}
\@writefile{lot}{\selectlanguage *{spanish}}
\HyPL@Entry{1<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}Motivación}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Objetivo}{4}{section.2}\protected@file@percent }
\citation{poole1998}
\citation{bishop2006pattern}
\@writefile{toc}{\contentsline {section}{\numberline {3}Marco teórico}{5}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Inteligencia Artificial}{5}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Aprendizaje automático}{5}{subsubsection.3.1.1}\protected@file@percent }
\newlabel{machinelearning}{{3.1.1}{5}{Aprendizaje automático}{subsubsection.3.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Diagrama de flujo de una aplicación de \textit  {Machine Learning}.}}{5}{figure.1}\protected@file@percent }
\newlabel{fig:flowchartml.}{{1}{5}{Diagrama de flujo de una aplicación de \textit {Machine Learning}}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Preprocesamiento}{6}{subsection.3.2}\protected@file@percent }
\newlabel{preprocessing}{{3.2}{6}{Preprocesamiento}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Aprendizaje supervisado}{6}{subsection.3.3}\protected@file@percent }
\newlabel{supervised}{{3.3}{6}{Aprendizaje supervisado}{subsection.3.3}{}}
\citation{norman2019aprendizaje}
\citation{GitHubpa25:online}
\citation{GitHubpa25:online}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Clasificación}{7}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Ejemplo de clasificación binaria.}}{7}{figure.2}\protected@file@percent }
\newlabel{fig:binaryclassification.}{{2}{7}{Ejemplo de clasificación binaria}{figure.2}{}}
\citation{GitHubpa25:online}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Ventajas y desventajas de los algoritmos de clasificación.}}{8}{figure.3}\protected@file@percent }
\newlabel{fig:proconsclassification.}{{3}{8}{Ventajas y desventajas de los algoritmos de clasificación}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Ejemplo de regresión lineal.}}{9}{figure.4}\protected@file@percent }
\newlabel{fig:regressionlinear.}{{4}{9}{Ejemplo de regresión lineal}{figure.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Regresión}{9}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Ventajas y desventajas de los algoritmos de regresión.}}{10}{figure.5}\protected@file@percent }
\newlabel{fig:proconsregression.}{{5}{10}{Ventajas y desventajas de los algoritmos de regresión}{figure.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Aprendizaje no supervisado}{11}{subsection.3.4}\protected@file@percent }
\newlabel{unsupervised}{{3.4}{11}{Aprendizaje no supervisado}{subsection.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Detección de anomalías}{11}{subsubsection.3.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Ventajas y desventajas de los algoritmos de detección de anomalías.}}{12}{figure.6}\protected@file@percent }
\newlabel{fig:proconsanomaly.}{{6}{12}{Ventajas y desventajas de los algoritmos de detección de anomalías}{figure.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Reducción de dimensionalidad }{12}{subsubsection.3.4.2}\protected@file@percent }
\citation{trejoml}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Reducción de dimensionalidad de 3D a 2D.}}{13}{figure.7}\protected@file@percent }
\newlabel{fig:reduxdimension.}{{7}{13}{Reducción de dimensionalidad de 3D a 2D}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Pro y contras de algoritmos de reducción de dimensionalidad.}}{13}{figure.8}\protected@file@percent }
\newlabel{fig:proconsreduxdim.}{{8}{13}{Pro y contras de algoritmos de reducción de dimensionalidad}{figure.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}\textit  {Clustering}}{13}{subsubsection.3.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Dendograma generado por \textit  {clustering} jerárquico.}}{14}{figure.9}\protected@file@percent }
\newlabel{fig:dendogram.}{{9}{14}{Dendograma generado por \textit {clustering} jerárquico}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Clustering basado en densidades.}}{15}{figure.10}\protected@file@percent }
\newlabel{fig:DBSCAN.}{{10}{15}{Clustering basado en densidades}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Pros y contras de los algoritmos de \textit  {clustering}.}}{15}{figure.11}\protected@file@percent }
\newlabel{fig:proconsclustering.}{{11}{15}{Pros y contras de los algoritmos de \textit {clustering}}{figure.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Selección de algoritmo en base al \textit  {dataset}}{15}{subsection.3.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Diagrama general de algoritmos de aprendizaje supervisado y no supervisado.}}{16}{figure.12}\protected@file@percent }
\newlabel{fig:maindiagram.}{{12}{16}{Diagrama general de algoritmos de aprendizaje supervisado y no supervisado}{figure.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1}Algoritmos supervisados}{17}{subsubsection.3.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Diagrama general de los algoritmos de regresión.}}{17}{figure.13}\protected@file@percent }
\newlabel{fig:regressiondiagram.}{{13}{17}{Diagrama general de los algoritmos de regresión}{figure.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Diagrama general de los algoritmos de clasificación.}}{18}{figure.14}\protected@file@percent }
\newlabel{fig:classificationdiagram.}{{14}{18}{Diagrama general de los algoritmos de clasificación}{figure.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.2}Algoritmos no supervisados}{19}{subsubsection.3.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Diagrama general de los algoritmos de reducción de dimensión.}}{19}{figure.15}\protected@file@percent }
\newlabel{fig:dimreduxdiagram.}{{15}{19}{Diagrama general de los algoritmos de reducción de dimensión}{figure.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Diagrama general de los algoritmos de \textit  {clustering}.}}{19}{figure.16}\protected@file@percent }
\newlabel{fig:clusteringdiagram.}{{16}{19}{Diagrama general de los algoritmos de \textit {clustering}}{figure.16}{}}
\citation{rosebrock2017deep}
\citation{matich}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Diagrama general de los algoritmos de detección de anomalías.}}{20}{figure.17}\protected@file@percent }
\newlabel{fig:anomalydiagram.}{{17}{20}{Diagrama general de los algoritmos de detección de anomalías}{figure.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Redes neuronales}{20}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Arquitectura simple de red neuronal. \cite  {matich}}}{21}{figure.18}\protected@file@percent }
\newlabel{fig:nn}{{18}{21}{Arquitectura simple de red neuronal. \cite {matich}}{figure.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Relación con la biología}{21}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Estructura de una neurona biológica.}}{22}{figure.19}\protected@file@percent }
\newlabel{fig:realneuron}{{19}{22}{Estructura de una neurona biológica}{figure.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Modelos artificiales}{22}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Simple NN.}}{23}{figure.20}\protected@file@percent }
\newlabel{fig:simplenn}{{20}{23}{Simple NN}{figure.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Funciones de activación}{23}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces \textbf  {Arriba-izquierda}: Función escalón. \textbf  {Arriba-derecha}: Función sigmoidea. \textbf  {Medio-izquierda}: Tangente hiperbólica. \textbf  {Medio-derecha}: activación ReLU (función activación más usada en \textit  {Deep Learning}). \textbf  {Abajo-izquierda}: Leaky ReLU, variante de ReLU que permite valores negativos. \textbf  {Abajo-derecha}: ELU, otra variante de ReLU que obtiene mejor performance que Leaky ReLU.}}{24}{figure.21}\protected@file@percent }
\newlabel{fig:typesfactivation}{{21}{24}{\textbf {Arriba-izquierda}: Función escalón. \textbf {Arriba-derecha}: Función sigmoidea. \textbf {Medio-izquierda}: Tangente hiperbólica. \textbf {Medio-derecha}: activación ReLU (función activación más usada en \textit {Deep Learning}). \textbf {Abajo-izquierda}: Leaky ReLU, variante de ReLU que permite valores negativos. \textbf {Abajo-derecha}: ELU, otra variante de ReLU que obtiene mejor performance que Leaky ReLU}{figure.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Arquitecturas de redes \textit  {feedforward}}{25}{subsection.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Un ejemplo de una red neuronal \textit  {feedforward}.}}{26}{figure.22}\protected@file@percent }
\newlabel{fig:nnff}{{22}{26}{Un ejemplo de una red neuronal \textit {feedforward}}{figure.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Redes multicapa}{26}{subsection.4.5}\protected@file@percent }
\citation{sgd}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Función pérdida}{27}{subsection.4.6}\protected@file@percent }
\newlabel{funcperdida}{{9}{28}{Función pérdida}{equation.4.9}{}}
\citation{gdanalogy}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Descenso de gradiente}{29}{subsection.4.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Representación gráfica del descenso de gradiente.}}{31}{figure.23}\protected@file@percent }
\newlabel{fig:gd}{{23}{31}{Representación gráfica del descenso de gradiente}{figure.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Ajuste de la tasa de aprendizaje.}}{31}{figure.24}\protected@file@percent }
\newlabel{fig:lr}{{24}{31}{Ajuste de la tasa de aprendizaje}{figure.24}{}}
\citation{sgd}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}Backpropagation}{32}{subsection.4.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Las activaciones se propagan hacía adelante, pero los gradientes fluyen hacía atrás.}}{32}{figure.25}\protected@file@percent }
\newlabel{fig:back}{{25}{32}{Las activaciones se propagan hacía adelante, pero los gradientes fluyen hacía atrás}{figure.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Representación de grafo simple.}}{33}{figure.26}\protected@file@percent }
\newlabel{fig:func}{{26}{33}{Representación de grafo simple}{figure.26}{}}
\newlabel{dj/dy}{{16}{33}{Backpropagation}{equation.4.16}{}}
\newlabel{dJdD}{{17}{33}{Backpropagation}{equation.4.17}{}}
\newlabel{dJ/dW}{{26}{34}{Backpropagation}{equation.4.26}{}}
\newlabel{dJ/db}{{27}{34}{Backpropagation}{equation.4.27}{}}
\citation{quora}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9}Descenso de gradiente estocástico (SGD)}{35}{subsection.4.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.10}Sobreajuste y bajo-ajuste}{36}{subsection.4.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Distintas representaciones del ajuste en un mismo modelo.}}{36}{figure.27}\protected@file@percent }
\newlabel{fig:fitting}{{27}{36}{Distintas representaciones del ajuste en un mismo modelo}{figure.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.11}Regularización}{36}{subsection.4.11}\protected@file@percent }
\citation{rosebrock2017deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12}Los cuatro ingredientes de una red neuronal}{37}{subsection.4.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.12.1}Conjunto de datos}{37}{subsubsection.4.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.12.2}Función de pérdida}{37}{subsubsection.4.12.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.12.3}Modelo/Arquitectura}{37}{subsubsection.4.12.3}\protected@file@percent }
\citation{rosebrock2017deep}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.12.4}Método de optimización}{38}{subsubsection.4.12.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.13}Redes Neuronales Convolucionales}{38}{subsection.4.13}\protected@file@percent }
\citation{keller}
\citation{Cogneethi2019Aug}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.13.1}Convolución 1D}{39}{subsubsection.4.13.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Vectores de convolución unidimensional con kernel simple.}}{40}{figure.28}\protected@file@percent }
\newlabel{fig:conv1dk1}{{28}{40}{Vectores de convolución unidimensional con kernel simple}{figure.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Vectores de convolución unidimensional con kernel doble.}}{40}{figure.29}\protected@file@percent }
\newlabel{fig:conv1dk2}{{29}{40}{Vectores de convolución unidimensional con kernel doble}{figure.29}{}}
\citation{SOOutputConv}
\citation{andrianaivo2019architecture}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Vectores de convolución unidimensional con kernel triple.}}{41}{figure.30}\protected@file@percent }
\newlabel{fig:conv1dk3}{{30}{41}{Vectores de convolución unidimensional con kernel triple}{figure.30}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.13.2}Convolución 2D}{41}{subsubsection.4.13.2}\protected@file@percent }
\citation{Saha2020Oct}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Vectores de convolución bidimensional con kernel $3 \times 3$.}}{42}{figure.31}\protected@file@percent }
\newlabel{fig:conv2d}{{31}{42}{Vectores de convolución bidimensional con kernel $3 \times 3$}{figure.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Imagen RGB $4 \times 4 \times 3$.}}{42}{figure.32}\protected@file@percent }
\newlabel{fig:conv2dimg}{{32}{42}{Imagen RGB $4 \times 4 \times 3$}{figure.32}{}}
\citation{karpathy:rnn}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Movimiento del kernel.}}{43}{figure.33}\protected@file@percent }
\newlabel{fig:kernelmove}{{33}{43}{Movimiento del kernel}{figure.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.14}Redes Neuronales Recurrentes}{43}{subsection.4.14}\protected@file@percent }
\citation{karpathy:rnn}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.14.1}Arquitecturas}{44}{subsubsection.4.14.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces Tipos de arquitecturas para una \textit  {RNN}.}}{45}{figure.34}\protected@file@percent }
\newlabel{fig:rnnarch}{{34}{45}{Tipos de arquitecturas para una \textit {RNN}}{figure.34}{}}
\citation{olahlstm}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.14.2}Funcionamiento}{46}{subsubsection.4.14.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Unidad funcional de \textit  {RNN}.}}{46}{figure.35}\protected@file@percent }
\newlabel{fig:rnnunit}{{35}{46}{Unidad funcional de \textit {RNN}}{figure.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Una \textit  {RNN} desenrrollada.}}{46}{figure.36}\protected@file@percent }
\newlabel{fig:rnnunrolled}{{36}{46}{Una \textit {RNN} desenrrollada}{figure.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces Unidad funcional \textit  {RNN} detallada.}}{47}{figure.37}\protected@file@percent }
\newlabel{fig:rnnunitv2}{{37}{47}{Unidad funcional \textit {RNN} detallada}{figure.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces Unidad funcional \textit  {RNN} detallada.}}{48}{figure.38}\protected@file@percent }
\newlabel{fig:rnnexample}{{38}{48}{Unidad funcional \textit {RNN} detallada}{figure.38}{}}
\citation{geron}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.14.3}Entrenamiento}{49}{subsubsection.4.14.3}\protected@file@percent }
\citation{phi:rnn}
\@writefile{lof}{\contentsline {figure}{\numberline {39}{\ignorespaces \textit  {Backpropagation} a través del tiempo.}}{50}{figure.39}\protected@file@percent }
\newlabel{fig:BPTT}{{39}{50}{\textit {Backpropagation} a través del tiempo}{figure.39}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.14.4}Desvanecimiento del gradiente}{50}{subsubsection.4.14.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {40}{\ignorespaces \textit  {RNN} siendo alimentada con las palabras de la oración.}}{51}{figure.40}\protected@file@percent }
\newlabel{fig:rnnvanishing1}{{40}{51}{\textit {RNN} siendo alimentada con las palabras de la oración}{figure.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {41}{\ignorespaces Predicción de la \textit  {RNN}.}}{51}{figure.41}\protected@file@percent }
\newlabel{fig:rnnvanishing2}{{41}{51}{Predicción de la \textit {RNN}}{figure.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {42}{\ignorespaces Estado oculto final de la \textit  {RNN}.}}{52}{figure.42}\protected@file@percent }
\newlabel{fig:rnnvanishing3}{{42}{52}{Estado oculto final de la \textit {RNN}}{figure.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {43}{\ignorespaces Desvanecimiento del gradiente desde las capas superiores a las inferiores.}}{52}{figure.43}\protected@file@percent }
\newlabel{fig:rnnvanishing4}{{43}{52}{Desvanecimiento del gradiente desde las capas superiores a las inferiores}{figure.43}{}}
\citation{olahlstm}
\@writefile{lof}{\contentsline {figure}{\numberline {44}{\ignorespaces El gradiente se achica a medida que se propaga hacia atrás en el tiempo.}}{53}{figure.44}\protected@file@percent }
\newlabel{fig:rnnvanishing5}{{44}{53}{El gradiente se achica a medida que se propaga hacia atrás en el tiempo}{figure.44}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.14.5}LSTM}{53}{subsubsection.4.14.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {45}{\ignorespaces Celda \textit  {LSTM}.}}{54}{figure.45}\protected@file@percent }
\newlabel{fig:lstmcell}{{45}{54}{Celda \textit {LSTM}}{figure.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {46}{\ignorespaces Celda de estado.}}{55}{figure.46}\protected@file@percent }
\newlabel{fig:lstm1}{{46}{55}{Celda de estado}{figure.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {47}{\ignorespaces Puerta del olvido.}}{55}{figure.47}\protected@file@percent }
\newlabel{fig:lstm2}{{47}{55}{Puerta del olvido}{figure.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {48}{\ignorespaces Puerta de entrada.}}{56}{figure.48}\protected@file@percent }
\newlabel{fig:lstm3}{{48}{56}{Puerta de entrada}{figure.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {49}{\ignorespaces Actualización de la celda.}}{57}{figure.49}\protected@file@percent }
\newlabel{fig:lstm4}{{49}{57}{Actualización de la celda}{figure.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {50}{\ignorespaces Puerta de salida.}}{57}{figure.50}\protected@file@percent }
\newlabel{fig:lstm5}{{50}{57}{Puerta de salida}{figure.50}{}}
\citation{geron}
\citation{hadamard}
\citation{olahlstm}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.14.6}GRU}{58}{subsubsection.4.14.6}\protected@file@percent }
\citation{geron}
\@writefile{lof}{\contentsline {figure}{\numberline {51}{\ignorespaces Celda \textit  {GRU}.}}{59}{figure.51}\protected@file@percent }
\newlabel{fig:lstm5}{{51}{59}{Celda \textit {GRU}}{figure.51}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Desarrollo}{59}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Limpieza de datos}{59}{subsection.5.1}\protected@file@percent }
\bibdata{tesis}
\bibcite{poole1998}{{1}{1998}{{Poole et~al.}}{{Poole, Goebel, and Mackworth}}}
\bibcite{bishop2006pattern}{{2}{2006}{{Bishop}}{{}}}
\bibcite{norman2019aprendizaje}{{3}{2019}{{Norman and Bolivar}}{{}}}
\bibcite{GitHubpa25:online}{{4}{2020}{{Gutiérrez}}{{}}}
\bibcite{trejoml}{{5}{2019}{{Trejo}}{{}}}
\bibcite{rosebrock2017deep}{{6}{2017}{{Rosebrock}}{{}}}
\bibcite{matich}{{7}{2001}{{Matich}}{{}}}
\bibcite{sgd}{{8}{2018}{{freeCodeCamp.org}}{{}}}
\bibcite{gdanalogy}{{9}{2020}{{Wikipedia}}{{}}}
\bibcite{quora}{{10}{2020}{{Quora}}{{}}}
\bibcite{keller}{{11}{2010}{{Keller}}{{}}}
\bibcite{Cogneethi2019Aug}{{12}{2019}{{Cogneethi}}{{}}}
\bibcite{SOOutputConv}{{13}{2021}{{StackOverflow}}{{}}}
\bibcite{andrianaivo2019architecture}{{14}{2019}{{Andrianaivo et~al.}}{{Andrianaivo, D'Autilia, and Palma}}}
\bibcite{Saha2020Oct}{{15}{2020}{{Saha}}{{}}}
\bibcite{karpathy:rnn}{{16}{2020}{{Karpathy}}{{}}}
\bibcite{olahlstm}{{17}{2015}{{Olah}}{{}}}
\bibcite{geron}{{18}{2019}{{Géron}}{{}}}
\bibcite{phi:rnn}{{19}{2019}{{Phi}}{{}}}
\bibcite{hadamard}{{20}{2021}{{had}}{{}}}
\bibstyle{unsrtnat}
\gdef \@abspage@last{63}
