\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\providecommand \oddpage@label [2]{}
\selectlanguage *{spanish}
\@writefile{toc}{\selectlanguage *{spanish}}
\@writefile{lof}{\selectlanguage *{spanish}}
\@writefile{lot}{\selectlanguage *{spanish}}
\HyPL@Entry{1<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}Motivación}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Objetivo}{4}{section.2}\protected@file@percent }
\citation{poole1998}
\citation{bishop2006pattern}
\@writefile{toc}{\contentsline {section}{\numberline {3}Clasificación de modelos de inteligencia artificial}{5}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Inteligencia Artificial}{5}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Aprendizaje automático}{5}{subsubsection.3.1.1}\protected@file@percent }
\newlabel{machinelearning}{{3.1.1}{5}{Aprendizaje automático}{subsubsection.3.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Diagrama de flujo de una aplicación de \textit  {Machine Learning}.}}{6}{figure.1}\protected@file@percent }
\newlabel{fig:flowchartml.}{{1}{6}{Diagrama de flujo de una aplicación de \textit {Machine Learning}}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Preprocesamiento}{6}{subsection.3.2}\protected@file@percent }
\newlabel{preprocessing}{{3.2}{6}{Preprocesamiento}{subsection.3.2}{}}
\citation{norman2019aprendizaje}
\citation{GitHubpa25:online}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Aprendizaje supervisado}{7}{subsection.3.3}\protected@file@percent }
\newlabel{supervised}{{3.3}{7}{Aprendizaje supervisado}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Clasificación}{7}{subsubsection.3.3.1}\protected@file@percent }
\citation{GitHubpa25:online}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Ejemplo de clasificación binaria.}}{8}{figure.2}\protected@file@percent }
\newlabel{fig:binaryclassification.}{{2}{8}{Ejemplo de clasificación binaria}{figure.2}{}}
\citation{GitHubpa25:online}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Ventajas y desventajas de los algoritmos de clasificación.}}{9}{figure.3}\protected@file@percent }
\newlabel{fig:proconsclassification.}{{3}{9}{Ventajas y desventajas de los algoritmos de clasificación}{figure.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Regresión}{9}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Ejemplo de regresión lineal.}}{10}{figure.4}\protected@file@percent }
\newlabel{fig:regressionlinear.}{{4}{10}{Ejemplo de regresión lineal}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Ventajas y desventajas de los algoritmos de regresión.}}{10}{figure.5}\protected@file@percent }
\newlabel{fig:proconsregression.}{{5}{10}{Ventajas y desventajas de los algoritmos de regresión}{figure.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Aprendizaje no supervisado}{11}{subsection.3.4}\protected@file@percent }
\newlabel{unsupervised}{{3.4}{11}{Aprendizaje no supervisado}{subsection.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Detección de anomalías}{11}{subsubsection.3.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Ventajas y desventajas de los algoritmos de detección de anomalías.}}{12}{figure.6}\protected@file@percent }
\newlabel{fig:proconsanomaly.}{{6}{12}{Ventajas y desventajas de los algoritmos de detección de anomalías}{figure.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Reducción de dimensionalidad }{12}{subsubsection.3.4.2}\protected@file@percent }
\citation{trejoml}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Reducción de dimensionalidad de 3D a 2D.}}{13}{figure.7}\protected@file@percent }
\newlabel{fig:reduxdimension.}{{7}{13}{Reducción de dimensionalidad de 3D a 2D}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Pro y contras de algoritmos de reducción de dimensionalidad.}}{13}{figure.8}\protected@file@percent }
\newlabel{fig:proconsreduxdim.}{{8}{13}{Pro y contras de algoritmos de reducción de dimensionalidad}{figure.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}\textit  {Clustering}}{13}{subsubsection.3.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Dendograma generado por \textit  {clustering} jerárquico.}}{14}{figure.9}\protected@file@percent }
\newlabel{fig:dendogram.}{{9}{14}{Dendograma generado por \textit {clustering} jerárquico}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Clustering basado en densidades.}}{15}{figure.10}\protected@file@percent }
\newlabel{fig:DBSCAN.}{{10}{15}{Clustering basado en densidades}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Pros y contras de los algoritmos de \textit  {clustering}.}}{15}{figure.11}\protected@file@percent }
\newlabel{fig:proconsclustering.}{{11}{15}{Pros y contras de los algoritmos de \textit {clustering}}{figure.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Selección de algoritmo en base al \textit  {dataset}}{15}{subsection.3.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Diagrama general de algoritmos de aprendizaje supervisado y no supervisado.}}{16}{figure.12}\protected@file@percent }
\newlabel{fig:maindiagram.}{{12}{16}{Diagrama general de algoritmos de aprendizaje supervisado y no supervisado}{figure.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1}Algoritmos supervisados}{17}{subsubsection.3.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Diagrama general de los algoritmos de regresión.}}{17}{figure.13}\protected@file@percent }
\newlabel{fig:regressiondiagram.}{{13}{17}{Diagrama general de los algoritmos de regresión}{figure.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Diagrama general de los algoritmos de clasificación.}}{18}{figure.14}\protected@file@percent }
\newlabel{fig:classificationdiagram.}{{14}{18}{Diagrama general de los algoritmos de clasificación}{figure.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.2}Algoritmos no supervisados}{19}{subsubsection.3.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Diagrama general de los algoritmos de reducción de dimensión.}}{19}{figure.15}\protected@file@percent }
\newlabel{fig:dimreduxdiagram.}{{15}{19}{Diagrama general de los algoritmos de reducción de dimensión}{figure.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Diagrama general de los algoritmos de \textit  {clustering}.}}{19}{figure.16}\protected@file@percent }
\newlabel{fig:clusteringdiagram.}{{16}{19}{Diagrama general de los algoritmos de \textit {clustering}}{figure.16}{}}
\citation{rosebrock2017deep}
\citation{matich}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Diagrama general de los algoritmos de detección de anomalías.}}{20}{figure.17}\protected@file@percent }
\newlabel{fig:anomalydiagram.}{{17}{20}{Diagrama general de los algoritmos de detección de anomalías}{figure.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Redes neuronales}{20}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Arquitectura simple de red neuronal. \cite  {matich}}}{21}{figure.18}\protected@file@percent }
\newlabel{fig:nn}{{18}{21}{Arquitectura simple de red neuronal. \cite {matich}}{figure.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Relación con la biología}{21}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Estructura de una neurona biológica.}}{22}{figure.19}\protected@file@percent }
\newlabel{fig:realneuron}{{19}{22}{Estructura de una neurona biológica}{figure.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Modelos artificiales}{22}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Simple NN.}}{23}{figure.20}\protected@file@percent }
\newlabel{fig:simplenn}{{20}{23}{Simple NN}{figure.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Funciones de activación}{23}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces \textbf  {Arriba-izquierda}: Función escalón. \textbf  {Arriba-derecha}: Función sigmoidea. \textbf  {Medio-izquierda}: Tangente hiperbólica. \textbf  {Medio-derecha}: activación ReLU (función activación más usada en \textit  {Deep Learning}). \textbf  {Abajo-izquierda}: Leaky ReLU, variante de ReLU que permite valores negativos. \textbf  {Abajo-derecha}: ELU, otra variante de ReLU que obtiene mejor performance que Leaky ReLU.}}{24}{figure.21}\protected@file@percent }
\newlabel{fig:typesfactivation}{{21}{24}{\textbf {Arriba-izquierda}: Función escalón. \textbf {Arriba-derecha}: Función sigmoidea. \textbf {Medio-izquierda}: Tangente hiperbólica. \textbf {Medio-derecha}: activación ReLU (función activación más usada en \textit {Deep Learning}). \textbf {Abajo-izquierda}: Leaky ReLU, variante de ReLU que permite valores negativos. \textbf {Abajo-derecha}: ELU, otra variante de ReLU que obtiene mejor performance que Leaky ReLU}{figure.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Arquitecturas de redes \textit  {feedforward}}{25}{subsection.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Un ejemplo de una red neuronal \textit  {feedforward}.}}{26}{figure.22}\protected@file@percent }
\newlabel{fig:nnff}{{22}{26}{Un ejemplo de una red neuronal \textit {feedforward}}{figure.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Redes multicapa}{26}{subsection.4.5}\protected@file@percent }
\citation{sgd}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Función pérdida}{27}{subsection.4.6}\protected@file@percent }
\newlabel{funcperdida}{{9}{28}{Función pérdida}{equation.4.9}{}}
\citation{gdanalogy}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Descenso de gradiente}{29}{subsection.4.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Representación gráfica del descenso de gradiente.}}{31}{figure.23}\protected@file@percent }
\newlabel{fig:gd}{{23}{31}{Representación gráfica del descenso de gradiente}{figure.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Ajuste de la tasa de aprendizaje.}}{31}{figure.24}\protected@file@percent }
\newlabel{fig:lr}{{24}{31}{Ajuste de la tasa de aprendizaje}{figure.24}{}}
\citation{sgd}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}Backpropagation}{32}{subsection.4.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Las activaciones se propagan hacía adelante, pero los gradientes fluyen hacía atrás.}}{32}{figure.25}\protected@file@percent }
\newlabel{fig:back}{{25}{32}{Las activaciones se propagan hacía adelante, pero los gradientes fluyen hacía atrás}{figure.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Representación de grafo simple.}}{33}{figure.26}\protected@file@percent }
\newlabel{fig:func}{{26}{33}{Representación de grafo simple}{figure.26}{}}
\newlabel{dj/dy}{{16}{33}{Backpropagation}{equation.4.16}{}}
\newlabel{dJdD}{{17}{33}{Backpropagation}{equation.4.17}{}}
\newlabel{dJ/dW}{{26}{34}{Backpropagation}{equation.4.26}{}}
\newlabel{dJ/db}{{27}{34}{Backpropagation}{equation.4.27}{}}
\citation{quora}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9}Descenso de gradiente estocástico (SGD)}{35}{subsection.4.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.10}Sobreajuste y bajo-ajuste}{36}{subsection.4.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Distintas representaciones del ajuste en un mismo modelo.}}{36}{figure.27}\protected@file@percent }
\newlabel{fig:fitting}{{27}{36}{Distintas representaciones del ajuste en un mismo modelo}{figure.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.11}Regularización}{36}{subsection.4.11}\protected@file@percent }
\citation{rosebrock2017deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12}Los cuatro ingredientes de una red neuronal}{37}{subsection.4.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.12.1}Conjunto de datos}{37}{subsubsection.4.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.12.2}Función de pérdida}{37}{subsubsection.4.12.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.12.3}Modelo/Arquitectura}{37}{subsubsection.4.12.3}\protected@file@percent }
\citation{rosebrock2017deep}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.12.4}Método de optimización}{38}{subsubsection.4.12.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Redes neuronales convolucionales}{38}{section.5}\protected@file@percent }
\citation{keller}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Convolución 1D}{39}{subsection.5.1}\protected@file@percent }
\citation{Cogneethi2019Aug}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Vectores de convolución unidimensional con kernel simple.}}{40}{figure.28}\protected@file@percent }
\newlabel{fig:conv1dk1}{{28}{40}{Vectores de convolución unidimensional con kernel simple}{figure.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Vectores de convolución unidimensional con kernel doble.}}{40}{figure.29}\protected@file@percent }
\newlabel{fig:conv1dk2}{{29}{40}{Vectores de convolución unidimensional con kernel doble}{figure.29}{}}
\citation{SOOutputConv}
\citation{andrianaivo2019architecture}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Vectores de convolución unidimensional con kernel triple.}}{41}{figure.30}\protected@file@percent }
\newlabel{fig:conv1dk3}{{30}{41}{Vectores de convolución unidimensional con kernel triple}{figure.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Convolución 2D}{41}{subsection.5.2}\protected@file@percent }
\citation{Saha2020Oct}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Vectores de convolución bidimensional con kernel $3 \times 3$.}}{42}{figure.31}\protected@file@percent }
\newlabel{fig:conv2d}{{31}{42}{Vectores de convolución bidimensional con kernel $3 \times 3$}{figure.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Imagen RGB $4 \times 4 \times 3$.}}{42}{figure.32}\protected@file@percent }
\newlabel{fig:conv2dimg}{{32}{42}{Imagen RGB $4 \times 4 \times 3$}{figure.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Movimiento del \textit  {kernel}.}}{43}{figure.33}\protected@file@percent }
\newlabel{fig:kernelmove}{{33}{43}{Movimiento del \textit {kernel}}{figure.33}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}\textit  {Padding}}{43}{subsubsection.5.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces Relleno o \textit  {padding}.}}{44}{figure.34}\protected@file@percent }
\newlabel{fig:padding}{{34}{44}{Relleno o \textit {padding}}{figure.34}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}\textit  {Stride}}{44}{subsubsection.5.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Convolución con \textit  {stride} de 2.}}{44}{figure.35}\protected@file@percent }
\newlabel{fig:stride}{{35}{44}{Convolución con \textit {stride} de 2}{figure.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Tipos de capas}{44}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Convolución}{45}{subsubsection.5.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Una capa está compuesta de una colección de \textit  {kernels}.}}{45}{figure.36}\protected@file@percent }
\newlabel{fig:layer-kernel}{{36}{45}{Una capa está compuesta de una colección de \textit {kernels}}{figure.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces \textbf  {Izquierda:} en cada capa convolucional de una \textit  {CNN}, hay $K$ \textit  {kernels} distintos. \textbf  {Medio:} Cada uno de los \textit  {kernels} es convolucionado con el vector de entrada. \textbf  {Derecha:} Cada \textit  {kernel} produce una salida 2D, llamada mapa de activación o \textit  {features}.}}{46}{figure.37}\protected@file@percent }
\newlabel{fig:conv-mechanism}{{37}{46}{\textbf {Izquierda:} en cada capa convolucional de una \textit {CNN}, hay $K$ \textit {kernels} distintos. \textbf {Medio:} Cada uno de los \textit {kernels} es convolucionado con el vector de entrada. \textbf {Derecha:} Cada \textit {kernel} produce una salida 2D, llamada mapa de activación o \textit {features}}{figure.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces Luego de obtener los $K$ mapas de activación, son apilados juntos para formar el volumen de entrada a la siguiente capa en la red.}}{47}{figure.38}\protected@file@percent }
\newlabel{fig:k-maps}{{38}{47}{Luego de obtener los $K$ mapas de activación, son apilados juntos para formar el volumen de entrada a la siguiente capa en la red}{figure.38}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Activación}{47}{subsubsection.5.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {39}{\ignorespaces Un ejemplo de un volumen de entrada desplazándose a través de una \texttt  {ACT} ReLU.}}{48}{figure.39}\protected@file@percent }
\newlabel{fig:relu-act}{{39}{48}{Un ejemplo de un volumen de entrada desplazándose a través de una \texttt {ACT} ReLU}{figure.39}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}\textit  {Fully-connected}}{48}{subsubsection.5.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4}\textit  {Pooling}}{48}{subsubsection.5.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {40}{\ignorespaces Tipos de \textit  {pooling}.}}{49}{figure.40}\protected@file@percent }
\newlabel{fig:type-pooling}{{40}{49}{Tipos de \textit {pooling}}{figure.40}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5}\textit  {Batch Normalization}}{49}{subsubsection.5.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.6}\textit  {Dropout}}{50}{subsubsection.5.3.6}\protected@file@percent }
\citation{wavenet}
\@writefile{lof}{\contentsline {figure}{\numberline {41}{\ignorespaces \textbf  {Izquierda:} Dos capas \texttt  {FC} sin \texttt  {DO}. \textbf  {Derecha:} Las mismas dos capas luego de realizar \textit  {dropout} sobre la mitad de las conexiones.}}{51}{figure.41}\protected@file@percent }
\newlabel{fig:type-pooling}{{41}{51}{\textbf {Izquierda:} Dos capas \texttt {FC} sin \texttt {DO}. \textbf {Derecha:} Las mismas dos capas luego de realizar \textit {dropout} sobre la mitad de las conexiones}{figure.41}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}\textit  {WaveNet} y capas convolucionales causales dilatadas}{51}{subsection.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {42}{\ignorespaces Paso de la información a través de la capa de convolución causal dilatada.}}{51}{figure.42}\protected@file@percent }
\newlabel{fig:causal-conv}{{42}{51}{Paso de la información a través de la capa de convolución causal dilatada}{figure.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {43}{\ignorespaces Visualización de una pila de capas causales convoluciones.}}{52}{figure.43}\protected@file@percent }
\newlabel{fig:stackcausal-conv}{{43}{52}{Visualización de una pila de capas causales convoluciones}{figure.43}{}}
\citation{karpathy:rnn}
\@writefile{lof}{\contentsline {figure}{\numberline {44}{\ignorespaces Visualización de una pila de capas causales convoluciones dilatadas.}}{53}{figure.44}\protected@file@percent }
\newlabel{fig:dilated-conv}{{44}{53}{Visualización de una pila de capas causales convoluciones dilatadas}{figure.44}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Redes neuronales recurrentes}{53}{section.6}\protected@file@percent }
\citation{karpathy:rnn}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Arquitecturas}{55}{subsection.6.1}\protected@file@percent }
\newlabel{rnnarchitecture}{{6.1}{55}{Arquitecturas}{subsection.6.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {45}{\ignorespaces Tipos de arquitecturas para una \textit  {RNN}.}}{55}{figure.45}\protected@file@percent }
\newlabel{fig:rnnarch}{{45}{55}{Tipos de arquitecturas para una \textit {RNN}}{figure.45}{}}
\citation{olahlstm}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Funcionamiento}{56}{subsection.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {46}{\ignorespaces Unidad funcional de \textit  {RNN}.}}{56}{figure.46}\protected@file@percent }
\newlabel{fig:rnnunit}{{46}{56}{Unidad funcional de \textit {RNN}}{figure.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {47}{\ignorespaces Una \textit  {RNN} desenrrollada.}}{57}{figure.47}\protected@file@percent }
\newlabel{fig:rnnunrolled}{{47}{57}{Una \textit {RNN} desenrrollada}{figure.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {48}{\ignorespaces Unidad funcional \textit  {RNN} detallada.}}{57}{figure.48}\protected@file@percent }
\newlabel{fig:rnnunitv2}{{48}{57}{Unidad funcional \textit {RNN} detallada}{figure.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {49}{\ignorespaces Unidad funcional \textit  {RNN} detallada.}}{59}{figure.49}\protected@file@percent }
\newlabel{fig:rnnexample}{{49}{59}{Unidad funcional \textit {RNN} detallada}{figure.49}{}}
\citation{geron}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Entrenamiento}{60}{subsection.6.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {50}{\ignorespaces \textit  {Backpropagation} a través del tiempo.}}{60}{figure.50}\protected@file@percent }
\newlabel{fig:BPTT}{{50}{60}{\textit {Backpropagation} a través del tiempo}{figure.50}{}}
\citation{phi:rnn}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Desvanecimiento del gradiente}{61}{subsection.6.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {51}{\ignorespaces \textit  {RNN} siendo alimentada con las palabras de la oración.}}{61}{figure.51}\protected@file@percent }
\newlabel{fig:rnnvanishing1}{{51}{61}{\textit {RNN} siendo alimentada con las palabras de la oración}{figure.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {52}{\ignorespaces Predicción de la \textit  {RNN}.}}{62}{figure.52}\protected@file@percent }
\newlabel{fig:rnnvanishing2}{{52}{62}{Predicción de la \textit {RNN}}{figure.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {53}{\ignorespaces Estado oculto final de la \textit  {RNN}.}}{62}{figure.53}\protected@file@percent }
\newlabel{fig:rnnvanishing3}{{53}{62}{Estado oculto final de la \textit {RNN}}{figure.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {54}{\ignorespaces Desvanecimiento del gradiente desde las capas superiores a las inferiores.}}{63}{figure.54}\protected@file@percent }
\newlabel{fig:rnnvanishing4}{{54}{63}{Desvanecimiento del gradiente desde las capas superiores a las inferiores}{figure.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {55}{\ignorespaces El gradiente se achica a medida que se propaga hacia atrás en el tiempo.}}{63}{figure.55}\protected@file@percent }
\newlabel{fig:rnnvanishing5}{{55}{63}{El gradiente se achica a medida que se propaga hacia atrás en el tiempo}{figure.55}{}}
\citation{olahlstm}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Tipos de \textit  {RNNs}}{64}{subsection.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.1}LSTM}{64}{subsubsection.6.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {56}{\ignorespaces Celda \texttt  {LSTM}.}}{64}{figure.56}\protected@file@percent }
\newlabel{fig:lstmcell}{{56}{64}{Celda \texttt {LSTM}}{figure.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {57}{\ignorespaces Celda de estado.}}{65}{figure.57}\protected@file@percent }
\newlabel{fig:lstm1}{{57}{65}{Celda de estado}{figure.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {58}{\ignorespaces Puerta del olvido.}}{66}{figure.58}\protected@file@percent }
\newlabel{fig:lstm2}{{58}{66}{Puerta del olvido}{figure.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {59}{\ignorespaces Puerta de entrada.}}{66}{figure.59}\protected@file@percent }
\newlabel{fig:lstm3}{{59}{66}{Puerta de entrada}{figure.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {60}{\ignorespaces Actualización de la celda.}}{67}{figure.60}\protected@file@percent }
\newlabel{fig:lstm4}{{60}{67}{Actualización de la celda}{figure.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {61}{\ignorespaces Puerta de salida.}}{67}{figure.61}\protected@file@percent }
\newlabel{fig:lstm5}{{61}{67}{Puerta de salida}{figure.61}{}}
\citation{geron}
\citation{hadamard}
\citation{olahlstm}
\citation{geron}
\citation{geron}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.2}GRU}{69}{subsubsection.6.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {62}{\ignorespaces Celda \texttt  {GRU}.}}{69}{figure.62}\protected@file@percent }
\newlabel{fig:lstm5}{{62}{69}{Celda \texttt {GRU}}{figure.62}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Secuencias de entradas y salida}{70}{subsection.6.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {63}{\ignorespaces \textbf  {Superior-izquierda}: \textit  {seq-to-seq}. \textbf  {Superior-derecha}: \textit  {sec-to-vector}. \textbf  {Inferior-izquierda}: \textit  {vector-to-sec}. \textbf  {Inferior-derecha}: \textit  {encoder-decoder}.}}{70}{figure.63}\protected@file@percent }
\newlabel{fig:rnnnets}{{63}{70}{\textbf {Superior-izquierda}: \textit {seq-to-seq}. \textbf {Superior-derecha}: \textit {sec-to-vector}. \textbf {Inferior-izquierda}: \textit {vector-to-sec}. \textbf {Inferior-derecha}: \textit {encoder-decoder}}{figure.63}{}}
\citation{poole1998}
\@writefile{toc}{\contentsline {section}{\numberline {7}Series temporales}{71}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Clasificación del modelo}{71}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}Tipo de variables de entrada}{71}{subsubsection.7.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.2}Objetivo}{72}{subsubsection.7.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.3}Estructura}{72}{subsubsection.7.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.4}Cantidad de variables utilizadas como características}{73}{subsubsection.7.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.5}Horizonte de pronóstico}{73}{subsubsection.7.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.6}Estático \textit  {vs} Dinámico}{73}{subsubsection.7.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.7}Uniformidad en el tiempo}{74}{subsubsection.7.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Desarrollo}{74}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Breve introducción}{74}{subsection.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.1}Organización de la usina}{74}{subsubsection.8.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.2}Nomenclatura de defectos}{75}{subsubsection.8.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.3}Puntos de captaje}{75}{subsubsection.8.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Limpieza de datos}{76}{subsection.8.2}\protected@file@percent }
\bibdata{tesis}
\bibcite{poole1998}{{1}{1998}{{Poole et~al.}}{{Poole, Goebel, and Mackworth}}}
\bibcite{bishop2006pattern}{{2}{2006}{{Bishop}}{{}}}
\bibcite{norman2019aprendizaje}{{3}{2019}{{Norman and Bolivar}}{{}}}
\bibcite{GitHubpa25:online}{{4}{2020}{{Gutiérrez}}{{}}}
\bibcite{trejoml}{{5}{2019}{{Trejo}}{{}}}
\bibcite{rosebrock2017deep}{{6}{2017}{{Rosebrock}}{{}}}
\bibcite{matich}{{7}{2001}{{Matich}}{{}}}
\bibcite{sgd}{{8}{2018}{{freeCodeCamp.org}}{{}}}
\bibcite{gdanalogy}{{9}{2020}{{Wikipedia}}{{}}}
\bibcite{quora}{{10}{2020}{{Quora}}{{}}}
\bibcite{keller}{{11}{2010}{{Keller}}{{}}}
\bibcite{Cogneethi2019Aug}{{12}{2019}{{Cogneethi}}{{}}}
\bibcite{SOOutputConv}{{13}{2021}{{StackOverflow}}{{}}}
\bibcite{andrianaivo2019architecture}{{14}{2019}{{Andrianaivo et~al.}}{{Andrianaivo, D'Autilia, and Palma}}}
\bibcite{Saha2020Oct}{{15}{2020}{{Saha}}{{}}}
\bibcite{wavenet}{{16}{2019}{{Eddy}}{{}}}
\bibcite{karpathy:rnn}{{17}{2020}{{Karpathy}}{{}}}
\bibcite{olahlstm}{{18}{2015}{{Olah}}{{}}}
\bibcite{geron}{{19}{2019}{{Géron}}{{}}}
\bibcite{phi:rnn}{{20}{2019}{{Phi}}{{}}}
\bibcite{hadamard}{{21}{2021}{{had}}{{}}}
\bibstyle{unsrtnat}
\gdef \@abspage@last{79}
